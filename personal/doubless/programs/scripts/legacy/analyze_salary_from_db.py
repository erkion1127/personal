#!/usr/bin/env python3
"""
ê¸‰ì—¬ DB ê¸°ë°˜ ì´ìƒê±´ ë¶„ì„ í”„ë¡œê·¸ë¨

ê¸‰ì—¬ DBì™€ íšŒì› DBë¥¼ ì¡°ì¸í•˜ì—¬ ì¢…í•©ì ì¸ ì´ìƒê±´ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import sqlite3
import pandas as pd
from pathlib import Path
from datetime import datetime
from collections import defaultdict
import calendar
import json
import shutil
import re

def load_name_mapping_rules():
    """ì´ë¦„ ë§¤í•‘ ê·œì¹™ ë¡œë“œ"""
    rules_file = Path(__file__).parent / "name_mapping_rules.json"

    if not rules_file.exists():
        print("âš ï¸  ì´ë¦„ ë§¤í•‘ ê·œì¹™ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ê·œì¹™ ì‚¬ìš©")
        return {
            "normalization_rules": {
                "rules": [
                    {"pattern": "E$", "replacement": "", "enabled": True}
                ]
            },
            "known_mappings": {"mappings": {}}
        }

    with open(rules_file, 'r', encoding='utf-8') as f:
        return json.load(f)

def normalize_name(name, rules):
    """ì´ë¦„ ì •ê·œí™” (ê·œì¹™ ì ìš©)"""
    if pd.isna(name):
        return name

    normalized = str(name).strip()

    # ì •ê·œí™” ê·œì¹™ ì ìš©
    for rule in rules["normalization_rules"]["rules"]:
        if rule.get("enabled", True):
            pattern = rule["pattern"]
            replacement = rule["replacement"]
            normalized = re.sub(pattern, replacement, normalized)

    # ì•Œë ¤ì§„ ë§¤í•‘ ì ìš©
    mappings = rules["known_mappings"]["mappings"]
    if normalized in mappings:
        original = normalized
        normalized = mappings[normalized]
        return normalized, True, original  # (ì •ê·œí™”ëœ ì´ë¦„, ë§¤í•‘ ì ìš© ì—¬ë¶€, ì›ë³¸ ì´ë¦„)

    return normalized, False, name

def load_salary_and_members(salary_db_path, members_db_path, name_rules=None):
    """ê¸‰ì—¬ DBì™€ íšŒì› DBë¥¼ ì¡°ì¸í•˜ì—¬ ë¡œë“œ (ì´ë¦„ ì •ê·œí™” ì ìš©)"""
    conn = sqlite3.connect(salary_db_path)

    # íšŒì› DB ì—°ê²°
    conn.execute(f"ATTACH DATABASE '{members_db_path}' AS members_db")

    # ê¸‰ì—¬ ë°ì´í„° ë¨¼ì € ë¡œë“œ
    salary_query = """
        SELECT
            ë…„ë„, ì›”, íŠ¸ë ˆì´ë„ˆ, íšŒì›ëª…, ì„±ë³„,
            ë“±ë¡ì„¸ì…˜, ì´ì§„í–‰ì„¸ì…˜, ë‚¨ì€ì„¸ì…˜,
            ê²°ì œí˜•íƒœ, ë“±ë¡ë¹„ìš©, ê³µê¸‰ê°€, íšŒë‹¨ê°€, ë§¤ì¶œëŒ€ë¹„ìœ¨,
            ìˆ˜ì—…ë£Œ_ì •ì‚°, ë‹¹ì›”ì§„í–‰ì„¸ì…˜, ë‹¹ì›”ìˆ˜ì—…ë£Œ, ì´ë‹¬ì˜ë§¤ì¶œ
        FROM salary_records
        ORDER BY ë…„ë„, ì›”, íŠ¸ë ˆì´ë„ˆ, íšŒì›ëª…
    """
    salary_df = pd.read_sql(salary_query, conn)

    # ì´ë¦„ ì •ê·œí™” ì ìš©
    if name_rules:
        salary_df['ì›ë³¸_íšŒì›ëª…'] = salary_df['íšŒì›ëª…']
        normalized_results = salary_df['íšŒì›ëª…'].apply(lambda x: normalize_name(x, name_rules))

        # ì •ê·œí™” ê²°ê³¼ ë¶„ë¦¬
        salary_df['íšŒì›ëª…_ì •ê·œí™”'] = normalized_results.apply(lambda x: x[0])
        salary_df['ì´ë¦„_ë§¤í•‘_ì ìš©'] = normalized_results.apply(lambda x: x[1])
        salary_df['ë§¤í•‘_ì „_ì´ë¦„'] = normalized_results.apply(lambda x: x[2])
    else:
        salary_df['íšŒì›ëª…_ì •ê·œí™”'] = salary_df['íšŒì›ëª…']
        salary_df['ì´ë¦„_ë§¤í•‘_ì ìš©'] = False
        salary_df['ì›ë³¸_íšŒì›ëª…'] = salary_df['íšŒì›ëª…']

    # íšŒì› DB ë¡œë“œ
    members_query = """
        SELECT
            ì´ë¦„, ìƒíƒœ, ì„±ë³„, ì—°ë½ì²˜, ë³´ìœ ì´ìš©ê¶Œ,
            ìµœì¢…ë§Œë£Œì¼, ë‚¨ì€ì¼ìˆ˜, ìµœê·¼êµ¬ë§¤ì¼, ìµœê·¼ì¶œì„ì¼,
            ìƒë‹´ë‹´ë‹¹ì, ë‚˜ì´
        FROM members
    """
    members_df = pd.read_sql(members_query, conn)
    conn.close()

    # ì •ê·œí™”ëœ ì´ë¦„ìœ¼ë¡œ ì¡°ì¸
    result_df = salary_df.merge(
        members_df,
        left_on='íšŒì›ëª…_ì •ê·œí™”',
        right_on='ì´ë¦„',
        how='left',
        suffixes=('_ê¸‰ì—¬', '_íšŒì›DB')
    )

    # ì»¬ëŸ¼ëª… ì •ë¦¬
    result_df.rename(columns={
        'ì„±ë³„_ê¸‰ì—¬': 'ê¸‰ì—¬ìƒ_ì„±ë³„',
        'ì„±ë³„_íšŒì›DB': 'íšŒì›DB_ì„±ë³„',
        'ìƒíƒœ': 'íšŒì›ìƒíƒœ',
        'ìƒë‹´ë‹´ë‹¹ì': 'íšŒì›DB_ë‹´ë‹¹ì'
    }, inplace=True)

    return result_df

def get_month_end_date(year, month_str):
    """ì›” ë¬¸ìì—´(ì˜ˆ: '11ì›”')ì„ ë°›ì•„ í•´ë‹¹ ì›”ì˜ ë§ˆì§€ë§‰ ë‚ ì§œë¥¼ ë°˜í™˜"""
    month_num = int(month_str.replace('ì›”', ''))
    last_day = calendar.monthrange(year, month_num)[1]
    return datetime(year, month_num, last_day)

def is_expired_at_session_time(row):
    """ì„¸ì…˜ ì§„í–‰ ë‹¹ì‹œì— íšŒì›ê¶Œì´ ë§Œë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸"""
    # íšŒì› DBì— ì—†ìœ¼ë©´ íŒë‹¨ ë¶ˆê°€
    if pd.isna(row['ìµœì¢…ë§Œë£Œì¼']):
        return False

    try:
        # ìµœì¢…ë§Œë£Œì¼ íŒŒì‹±
        expire_date = pd.to_datetime(row['ìµœì¢…ë§Œë£Œì¼'])

        # ê¸‰ì—¬ ì›”ì˜ ë§ˆì§€ë§‰ ë‚  ê³„ì‚°
        month_end = get_month_end_date(int(row['ë…„ë„']), row['ì›”'])

        # ê¸‰ì—¬ ì›” ë§ˆì§€ë§‰ ë‚  ê¸°ì¤€ìœ¼ë¡œ ë§Œë£Œë˜ì—ˆìœ¼ë©´ True
        return expire_date < month_end
    except:
        return False

def detect_anomalies(df):
    """ì´ìƒê±´ íƒì§€"""
    anomalies = []

    # ì›”ë³„ë¡œ ì •ë ¬
    months = df['ì›”'].unique()

    # ì´ì „ ì›” ë°ì´í„° ì €ì¥ìš©
    prev_month_data = {}

    for month in sorted(months):
        month_df = df[df['ì›”'] == month]

        for idx, row in month_df.iterrows():
            issues = []

            # 1. ë‹¹ì›” ì§„í–‰ì„¸ì…˜ì´ ìˆëŠ”ë° ë‚¨ì€ì„¸ì…˜ì´ ìŒìˆ˜ (0ì€ ì •ìƒ - ì •í™•íˆ ì†Œì§„)
            if pd.notna(row['ë‹¹ì›”ì§„í–‰ì„¸ì…˜']) and row['ë‹¹ì›”ì§„í–‰ì„¸ì…˜'] > 0:
                if pd.notna(row['ë‚¨ì€ì„¸ì…˜']) and row['ë‚¨ì€ì„¸ì…˜'] < 0:
                    issues.append(f"ë‹¹ì›” {row['ë‹¹ì›”ì§„í–‰ì„¸ì…˜']:.0f}íšŒ ì§„í–‰í–ˆìœ¼ë‚˜ ë‚¨ì€ì„¸ì…˜ {row['ë‚¨ì€ì„¸ì…˜']:.0f}íšŒ (ì´ˆê³¼ ì‚¬ìš©)")

            # 2. íšŒì› DBì— ì—†ëŠ” ê²½ìš°
            in_db = pd.notna(row['íšŒì›ìƒíƒœ'])
            if not in_db:
                issues.append("íšŒì› DBì— ì¡´ì¬í•˜ì§€ ì•ŠìŒ (íƒˆí‡´ ë˜ëŠ” ì´ë¦„ ì˜¤íƒ€)")

            # 3. ì„¸ì…˜ ì§„í–‰ ë‹¹ì‹œ ë§Œë£Œëœ íšŒì›ì¸ë° ì„¸ì…˜ ì§„í–‰
            if in_db:
                if pd.notna(row['ë‹¹ì›”ì§„í–‰ì„¸ì…˜']) and row['ë‹¹ì›”ì§„í–‰ì„¸ì…˜'] > 0:
                    if is_expired_at_session_time(row):
                        issues.append(f"ì„¸ì…˜ ì§„í–‰ ë‹¹ì‹œ({row['ì›”']}) ì´ë¯¸ ë§Œë£Œëœ íšŒì› (ë§Œë£Œì¼: {row['ìµœì¢…ë§Œë£Œì¼']})")

            # 4. ë‹´ë‹¹ì ë¶ˆì¼ì¹˜
            if in_db and pd.notna(row['íšŒì›DB_ë‹´ë‹¹ì']) and row['íšŒì›DB_ë‹´ë‹¹ì'] != '-':
                if str(row['íŠ¸ë ˆì´ë„ˆ']) != str(row['íšŒì›DB_ë‹´ë‹¹ì']):
                    issues.append(f"ë‹´ë‹¹ì ë¶ˆì¼ì¹˜: ê¸‰ì—¬({row['íŠ¸ë ˆì´ë„ˆ']}) â‰  DB({row['íšŒì›DB_ë‹´ë‹¹ì']})")

            # 5. ì „ì›” ëŒ€ë¹„ ì²´í¬ (ì´ì „ ì›” ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
            member_key = f"{row['íŠ¸ë ˆì´ë„ˆ']}_{row['íšŒì›ëª…']}"
            if member_key in prev_month_data:
                prev_row = prev_month_data[member_key]

                # 10ì›”, 11ì›”ì€ ì–´ë·°ì§• ê°€ëŠ¥ì„±ìœ¼ë¡œ ë” ì—„ê²©í•˜ê²Œ ì²´í¬
                is_strict_month = row['ì›”'] in ['10ì›”', '11ì›”']

                # ì „ì›” ì”ì—¬ì„¸ì…˜ê³¼ ë‹¹ì›” ì§„í–‰ì„¸ì…˜, ë‹¹ì›” ì”ì—¬ì„¸ì…˜ì´ ëª¨ë‘ ìˆëŠ” ê²½ìš°
                if pd.notna(prev_row['ë‚¨ì€ì„¸ì…˜']) and pd.notna(row['ë‹¹ì›”ì§„í–‰ì„¸ì…˜']) and pd.notna(row['ë‚¨ì€ì„¸ì…˜']):
                    prev_remaining = prev_row['ë‚¨ì€ì„¸ì…˜']
                    current_sessions = row['ë‹¹ì›”ì§„í–‰ì„¸ì…˜']
                    current_remaining = row['ë‚¨ì€ì„¸ì…˜']

                    # ì˜ˆìƒ ì”ì—¬ = ì „ì›” ì”ì—¬ - ë‹¹ì›” ì§„í–‰
                    expected_remaining = prev_remaining - current_sessions

                    # 10ì›”, 11ì›”: ì „ì›” ì”ì—¬ë³´ë‹¤ ë§ì´ ì§„í–‰í•œ ê²½ìš° ëª¨ë‘ ì´ìƒ
                    if is_strict_month and current_sessions > 0:
                        if expected_remaining < 0:
                            # ì „ì›” ì”ì—¬ì„¸ì…˜ ë¶€ì¡±í•œë° ì§„í–‰
                            shortage = abs(expected_remaining)
                            issues.append(f"ğŸš¨ ì „ì›” ì”ì—¬ {prev_remaining:.0f}íšŒ ë¶€ì¡±í•œë° ë‹¹ì›” {current_sessions:.0f}íšŒ ì§„í–‰ (ë¶€ì¡±: {shortage:.0f}íšŒ) [ì–´ë·°ì§• ì˜ì‹¬]")

                    # ì‹¤ì œ ì”ì—¬ì™€ ì˜ˆìƒ ì”ì—¬ê°€ ë‹¤ë¥¸ ê²½ìš°
                    if abs(current_remaining - expected_remaining) > 0.5:  # ë¶€ë™ì†Œìˆ˜ì  ì˜¤ì°¨ ê³ ë ¤
                        diff = current_remaining - expected_remaining

                        if diff > 0:
                            # ì˜ˆìƒë³´ë‹¤ ë§ì´ ë‚¨ìŒ = ì„¸ì…˜ì´ ì¦ê°€í–ˆê±°ë‚˜ ì°¨ê°ì´ ì•ˆë¨
                            if is_strict_month:
                                issues.append(f"ğŸš¨ ì„¸ì…˜ ì°¨ê° ì´ìƒ: ì „ì›” ì”ì—¬ {prev_remaining:.0f}íšŒ - ë‹¹ì›” ì§„í–‰ {current_sessions:.0f}íšŒ = ì˜ˆìƒ {expected_remaining:.0f}íšŒ, ì‹¤ì œ {current_remaining:.0f}íšŒ (+{diff:.0f}íšŒ ì¦ê°€) [ì–´ë·°ì§• ì˜ì‹¬]")
                            else:
                                issues.append(f"ì„¸ì…˜ ì°¨ê° ì´ìƒ: ì „ì›” ì”ì—¬ {prev_remaining:.0f}íšŒ - ë‹¹ì›” ì§„í–‰ {current_sessions:.0f}íšŒ = ì˜ˆìƒ {expected_remaining:.0f}íšŒ, ì‹¤ì œ {current_remaining:.0f}íšŒ (+{diff:.0f}íšŒ ì¦ê°€)")
                        else:
                            # ì˜ˆìƒë³´ë‹¤ ì ê²Œ ë‚¨ìŒ = ì¶”ê°€ ì°¨ê° ë°œìƒ
                            issues.append(f"ì„¸ì…˜ ì¶”ê°€ ì°¨ê°: ì „ì›” ì”ì—¬ {prev_remaining:.0f}íšŒ - ë‹¹ì›” ì§„í–‰ {current_sessions:.0f}íšŒ = ì˜ˆìƒ {expected_remaining:.0f}íšŒ, ì‹¤ì œ {current_remaining:.0f}íšŒ ({diff:.0f}íšŒ ì¶”ê°€ ì°¨ê°)")

                # ì „ì›” ì”ì—¬ì„¸ì…˜ë³´ë‹¤ ë‹¹ì›” ì§„í–‰ì„¸ì…˜ì´ ë§ì€ ê²½ìš° (ì´ìš©ê¶Œ ì¶”ê°€ êµ¬ë§¤ ì—†ì´)
                elif pd.notna(prev_row['ë‚¨ì€ì„¸ì…˜']) and pd.notna(row['ë‹¹ì›”ì§„í–‰ì„¸ì…˜']):
                    if row['ë‹¹ì›”ì§„í–‰ì„¸ì…˜'] > prev_row['ë‚¨ì€ì„¸ì…˜']:
                        # 10ì›”, 11ì›”ì€ ë¬´ì¡°ê±´ ì´ìƒ
                        if is_strict_month:
                            shortage = row['ë‹¹ì›”ì§„í–‰ì„¸ì…˜'] - prev_row['ë‚¨ì€ì„¸ì…˜']
                            issues.append(f"ğŸš¨ ì „ì›” ì”ì—¬ {prev_row['ë‚¨ì€ì„¸ì…˜']:.0f}íšŒì¸ë° ë‹¹ì›” {row['ë‹¹ì›”ì§„í–‰ì„¸ì…˜']:.0f}íšŒ ì§„í–‰ (ì´ˆê³¼: {shortage:.0f}íšŒ) [ì–´ë·°ì§• ì˜ì‹¬]")
                        # ë‹¤ë¥¸ ë‹¬ì€ ë‹¹ì›” ì”ì—¬ê°€ ì—†ìœ¼ë©´ ë¬¸ì œ
                        elif pd.isna(row['ë‚¨ì€ì„¸ì…˜']) or row['ë‚¨ì€ì„¸ì…˜'] <= 0:
                            issues.append(f"ì „ì›” ì”ì—¬ {prev_row['ë‚¨ì€ì„¸ì…˜']:.0f}íšŒ ì´ˆê³¼ ì§„í–‰: ë‹¹ì›” {row['ë‹¹ì›”ì§„í–‰ì„¸ì…˜']:.0f}íšŒ ì§„í–‰")

            # 6. ë‹¹ì›”ìˆ˜ì—…ë£Œê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ê±°ë‚˜ ë‚®ì€ ê²½ìš°
            if pd.notna(row['ë‹¹ì›”ì§„í–‰ì„¸ì…˜']) and pd.notna(row['ë‹¹ì›”ìˆ˜ì—…ë£Œ']) and pd.notna(row['íšŒë‹¨ê°€']):
                if row['ë‹¹ì›”ì§„í–‰ì„¸ì…˜'] > 0 and row['íšŒë‹¨ê°€'] > 0:
                    expected = row['ë‹¹ì›”ì§„í–‰ì„¸ì…˜'] * row['íšŒë‹¨ê°€'] * row['ë§¤ì¶œëŒ€ë¹„ìœ¨']
                    actual = row['ë‹¹ì›”ìˆ˜ì—…ë£Œ']
                    # 10% ì´ìƒ ì°¨ì´ë‚˜ë©´ ì´ìƒ
                    if abs(expected - actual) / expected > 0.1:
                        issues.append(f"ê¸‰ì—¬ ê³„ì‚° ì´ìƒ: ì˜ˆìƒ {expected:,.0f}ì› vs ì‹¤ì œ {actual:,.0f}ì›")

            if issues:
                anomaly = {
                    'ë…„ë„': row['ë…„ë„'],
                    'ì›”': row['ì›”'],
                    'íŠ¸ë ˆì´ë„ˆ': row['íŠ¸ë ˆì´ë„ˆ'],
                    'íšŒì›ëª…': row['íšŒì›ëª…'],
                    'ë‹¹ì›”ì§„í–‰ì„¸ì…˜': row['ë‹¹ì›”ì§„í–‰ì„¸ì…˜'],
                    'ë‚¨ì€ì„¸ì…˜': row['ë‚¨ì€ì„¸ì…˜'],
                    'ë‹¹ì›”ìˆ˜ì—…ë£Œ': row['ë‹¹ì›”ìˆ˜ì—…ë£Œ'],
                    'ë“±ë¡ë¹„ìš©': row['ë“±ë¡ë¹„ìš©'],
                    'ê³µê¸‰ê°€': row['ê³µê¸‰ê°€'],
                    'íšŒë‹¨ê°€': row['íšŒë‹¨ê°€'],
                    'íšŒì›ìƒíƒœ': row['íšŒì›ìƒíƒœ'],
                    'ì—°ë½ì²˜': row['ì—°ë½ì²˜'],
                    'ìµœì¢…ë§Œë£Œì¼': row['ìµœì¢…ë§Œë£Œì¼'],
                    'ë‚¨ì€ì¼ìˆ˜': row['ë‚¨ì€ì¼ìˆ˜'],
                    'ìµœê·¼ì¶œì„ì¼': row['ìµœê·¼ì¶œì„ì¼'],
                    'íšŒì›DB_ë‹´ë‹¹ì': row['íšŒì›DB_ë‹´ë‹¹ì'],
                    'in_db': in_db,
                    'issues': issues
                }
                anomalies.append(anomaly)

        # í˜„ì¬ ì›” ë°ì´í„°ë¥¼ ë‹¤ìŒ ì›”ì„ ìœ„í•´ ì €ì¥
        for idx, row in month_df.iterrows():
            member_key = f"{row['íŠ¸ë ˆì´ë„ˆ']}_{row['íšŒì›ëª…']}"
            prev_month_data[member_key] = row

    return anomalies

def save_anomalies_csv(anomalies, output_path):
    """ì´ìƒê±´ì„ CSV íŒŒì¼ë¡œ ì €ì¥ (ì—‘ì…€ì—ì„œ ì—´ê¸° í¸í•¨)"""
    import csv

    with open(output_path, 'w', encoding='utf-8-sig', newline='') as f:
        writer = csv.writer(f)

        # í—¤ë”
        writer.writerow([
            'ë…„ë„', 'ì›”', 'íŠ¸ë ˆì´ë„ˆ', 'íšŒì›ëª…', 'ë‹¹ì›”ì§„í–‰ì„¸ì…˜', 'ë‚¨ì€ì„¸ì…˜',
            'ë‹¹ì›”ìˆ˜ì—…ë£Œ', 'íšŒì›ìƒíƒœ', 'ì—°ë½ì²˜', 'ìµœì¢…ë§Œë£Œì¼', 'ìµœê·¼ì¶œì„ì¼',
            'íšŒì›DB_ë‹´ë‹¹ì', 'ë¬¸ì œì '
        ])

        # ë°ì´í„°
        for a in anomalies:
            issues_str = ' | '.join(a['issues'])
            writer.writerow([
                a['ë…„ë„'],
                a['ì›”'],
                a['íŠ¸ë ˆì´ë„ˆ'],
                a['íšŒì›ëª…'],
                f"{a['ë‹¹ì›”ì§„í–‰ì„¸ì…˜']:.0f}" if pd.notna(a['ë‹¹ì›”ì§„í–‰ì„¸ì…˜']) else '',
                f"{a['ë‚¨ì€ì„¸ì…˜']:.0f}" if pd.notna(a['ë‚¨ì€ì„¸ì…˜']) else '',
                f"{a['ë‹¹ì›”ìˆ˜ì—…ë£Œ']:,.0f}" if pd.notna(a['ë‹¹ì›”ìˆ˜ì—…ë£Œ']) else '',
                a['íšŒì›ìƒíƒœ'] if a['in_db'] else 'DBì—†ìŒ',
                a['ì—°ë½ì²˜'] if pd.notna(a['ì—°ë½ì²˜']) else '',
                a['ìµœì¢…ë§Œë£Œì¼'] if pd.notna(a['ìµœì¢…ë§Œë£Œì¼']) else '',
                a['ìµœê·¼ì¶œì„ì¼'] if pd.notna(a['ìµœê·¼ì¶œì„ì¼']) else '',
                a['íšŒì›DB_ë‹´ë‹¹ì'] if pd.notna(a['íšŒì›DB_ë‹´ë‹¹ì']) else '',
                issues_str
            ])

def save_metadata(report_dir, anomalies, total_records):
    """ë¶„ì„ ë©”íƒ€ë°ì´í„° ì €ì¥"""
    metadata = {
        'timestamp': datetime.now().isoformat(),
        'total_salary_records': total_records,
        'total_anomalies': len(anomalies),
        'anomalies_in_db': sum(1 for a in anomalies if a['in_db']),
        'anomalies_not_in_db': sum(1 for a in anomalies if not a['in_db']),
        'anomaly_rate': f"{len(anomalies)*100/total_records:.1f}%",
        'issue_types': {}
    }

    # ì´ìƒ ìœ í˜•ë³„ í†µê³„
    issue_types = defaultdict(int)
    for a in anomalies:
        for issue in a['issues']:
            if 'íšŒì› DBì— ì¡´ì¬í•˜ì§€ ì•ŠìŒ' in issue:
                issue_types['íšŒì› DB ì—†ìŒ'] += 1
            elif 'ì„¸ì…˜ ì§„í–‰ ë‹¹ì‹œ' in issue and 'ì´ë¯¸ ë§Œë£Œ' in issue:
                issue_types['ì„¸ì…˜ ì§„í–‰ ë‹¹ì‹œ ë§Œë£Œëœ íšŒì›'] += 1
            elif 'ë‹´ë‹¹ì ë¶ˆì¼ì¹˜' in issue:
                issue_types['ë‹´ë‹¹ì ë¶ˆì¼ì¹˜'] += 1
            elif 'ì–´ë·°ì§• ì˜ì‹¬' in issue:
                issue_types['ğŸš¨ ì–´ë·°ì§• ì˜ì‹¬ (10-11ì›”)'] += 1
            elif 'ì„¸ì…˜ ì°¨ê° ì´ìƒ' in issue:
                issue_types['ì„¸ì…˜ ì°¨ê° ì´ìƒ (ë¹„ì •ìƒ ì¦ê°€)'] += 1
            elif 'ì„¸ì…˜ ì¶”ê°€ ì°¨ê°' in issue:
                issue_types['ì„¸ì…˜ ì¶”ê°€ ì°¨ê°'] += 1
            elif 'ì „ì›” ì”ì—¬' in issue and 'ì´ˆê³¼ ì§„í–‰' in issue:
                issue_types['ì „ì›” ì”ì—¬ ì´ˆê³¼ ì§„í–‰'] += 1
            elif 'ê¸‰ì—¬ ê³„ì‚° ì´ìƒ' in issue:
                issue_types['ê¸‰ì—¬ ê³„ì‚° ì˜¤ë¥˜'] += 1
            elif 'ë‚¨ì€ì„¸ì…˜ 0' in issue or 'ë‚¨ì€ì„¸ì…˜ -' in issue:
                issue_types['ì„¸ì…˜ ì¢…ë£Œ í›„ ì§„í–‰'] += 1

    metadata['issue_types'] = dict(issue_types)

    # JSON ì €ì¥
    meta_file = report_dir / "ë¶„ì„_ë©”íƒ€ë°ì´í„°.json"
    with open(meta_file, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)

def save_analysis_report(anomalies, output_path):
    """ë¶„ì„ ë³´ê³ ì„œ ì €ì¥"""
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("="*120 + "\n")
        f.write("Doubless ê¸‰ì—¬ ì´ìƒê±´ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ (DB ê¸°ë°˜)\n")
        f.write(f"ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("="*120 + "\n\n")

        # ì „ì²´ í†µê³„
        total = len(anomalies)
        in_db = sum(1 for a in anomalies if a['in_db'])
        not_in_db = total - in_db

        f.write("ğŸ“Š ì „ì²´ í†µê³„\n")
        f.write("="*120 + "\n")
        f.write(f"ì´ ì´ìƒê±´: {total}ê±´\n")
        f.write(f"  - íšŒì› DB ì¡´ì¬: {in_db}ê±´ ({in_db*100/total:.1f}%)\n")
        f.write(f"  - íšŒì› DB ì—†ìŒ: {not_in_db}ê±´ ({not_in_db*100/total:.1f}%)\n\n")

        # ì´ìƒ ìœ í˜•ë³„ í†µê³„
        f.write("ğŸ“‹ ì´ìƒ ìœ í˜•ë³„ í†µê³„\n")
        f.write("="*120 + "\n")
        issue_types = defaultdict(int)
        for a in anomalies:
            for issue in a['issues']:
                # ì´ìŠˆ ìœ í˜• ë¶„ë¥˜
                if 'íšŒì› DBì— ì¡´ì¬í•˜ì§€ ì•ŠìŒ' in issue:
                    issue_types['íšŒì› DB ì—†ìŒ'] += 1
                elif 'ì„¸ì…˜ ì§„í–‰ ë‹¹ì‹œ' in issue and 'ì´ë¯¸ ë§Œë£Œ' in issue:
                    issue_types['ì„¸ì…˜ ì§„í–‰ ë‹¹ì‹œ ë§Œë£Œëœ íšŒì›'] += 1
                elif 'ë‹´ë‹¹ì ë¶ˆì¼ì¹˜' in issue:
                    issue_types['ë‹´ë‹¹ì ë¶ˆì¼ì¹˜'] += 1
                elif 'ì–´ë·°ì§• ì˜ì‹¬' in issue:
                    issue_types['ğŸš¨ ì–´ë·°ì§• ì˜ì‹¬ (10-11ì›”)'] += 1
                elif 'ì„¸ì…˜ ì°¨ê° ì´ìƒ' in issue:
                    issue_types['ì„¸ì…˜ ì°¨ê° ì´ìƒ (ë¹„ì •ìƒ ì¦ê°€)'] += 1
                elif 'ì„¸ì…˜ ì¶”ê°€ ì°¨ê°' in issue:
                    issue_types['ì„¸ì…˜ ì¶”ê°€ ì°¨ê°'] += 1
                elif 'ì „ì›” ì”ì—¬' in issue and 'ì´ˆê³¼ ì§„í–‰' in issue:
                    issue_types['ì „ì›” ì”ì—¬ ì´ˆê³¼ ì§„í–‰'] += 1
                elif 'ê¸‰ì—¬ ê³„ì‚° ì´ìƒ' in issue:
                    issue_types['ê¸‰ì—¬ ê³„ì‚° ì˜¤ë¥˜'] += 1
                elif 'ë‚¨ì€ì„¸ì…˜ 0' in issue or 'ë‚¨ì€ì„¸ì…˜ -' in issue:
                    issue_types['ì„¸ì…˜ ì¢…ë£Œ í›„ ì§„í–‰'] += 1

        for issue_type, count in sorted(issue_types.items(), key=lambda x: x[1], reverse=True):
            f.write(f"  {issue_type}: {count}ê±´\n")

        # íšŒì› DB ì—†ëŠ” ëª©ë¡
        if not_in_db > 0:
            f.write(f"\n\nâš ï¸  íšŒì› DBì— ì—†ëŠ” íšŒì› ëª©ë¡ ({not_in_db}ê±´)\n")
            f.write("="*120 + "\n")
            f.write("ê¸‰ì—¬ ë°ì´í„°ì—ëŠ” ìˆì§€ë§Œ íšŒì› DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì´ë¦„ ì˜¤íƒ€ ë˜ëŠ” íƒˆí‡´ íšŒì›)\n\n")

            not_in_db_list = [a for a in anomalies if not a['in_db']]
            for idx, a in enumerate(not_in_db_list, 1):
                f.write(f"{idx}. [{a['ì›”']}] {a['íŠ¸ë ˆì´ë„ˆ']} - {a['íšŒì›ëª…']}")
                f.write(f" (ë‹¹ì›” {a['ë‹¹ì›”ì§„í–‰ì„¸ì…˜']:.0f}íšŒ, ê¸‰ì—¬ {a['ë‹¹ì›”ìˆ˜ì—…ë£Œ']:,.0f}ì›)\n")

        # ì›”ë³„ ìƒì„¸ ë¶„ì„
        f.write(f"\n\n{'='*120}\n")
        f.write("ğŸ“… ì›”ë³„ ìƒì„¸ ë¶„ì„\n")
        f.write(f"{'='*120}\n\n")

        month_summary = defaultdict(list)
        for a in anomalies:
            if a['in_db']:  # DBì— ìˆëŠ” íšŒì›ë§Œ
                month_summary[a['ì›”']].append(a)

        for month in sorted(month_summary.keys()):
            month_anomalies = month_summary[month]
            f.write(f"\n{'='*120}\n")
            f.write(f"[{month}] - {len(month_anomalies)}ê±´\n")
            f.write(f"{'='*120}\n\n")

            trainer_summary = defaultdict(list)
            for a in month_anomalies:
                trainer_summary[a['íŠ¸ë ˆì´ë„ˆ']].append(a)

            for trainer, trainer_anomalies in sorted(trainer_summary.items()):
                f.write(f"\n{trainer} íŠ¸ë ˆì´ë„ˆ: {len(trainer_anomalies)}ê±´\n")
                f.write("-" * 120 + "\n\n")

                for idx, a in enumerate(trainer_anomalies, 1):
                    f.write(f"{idx}. {a['íšŒì›ëª…']}\n")
                    f.write(f"   {'â”€'*110}\n")

                    # ê¸‰ì—¬ ë°ì´í„°
                    f.write(f"   [ê¸‰ì—¬ ë°ì´í„°]\n")
                    f.write(f"   â€¢ ë‹¹ì›” ì§„í–‰ì„¸ì…˜: {a['ë‹¹ì›”ì§„í–‰ì„¸ì…˜']:.0f}íšŒ\n")
                    f.write(f"   â€¢ ë‚¨ì€ ì„¸ì…˜: {a['ë‚¨ì€ì„¸ì…˜']:.0f}íšŒ\n" if pd.notna(a['ë‚¨ì€ì„¸ì…˜']) else "   â€¢ ë‚¨ì€ ì„¸ì…˜: N/A\n")
                    f.write(f"   â€¢ ë‹¹ì›” ìˆ˜ì—…ë£Œ: {a['ë‹¹ì›”ìˆ˜ì—…ë£Œ']:,.0f}ì›\n" if pd.notna(a['ë‹¹ì›”ìˆ˜ì—…ë£Œ']) else "   â€¢ ë‹¹ì›” ìˆ˜ì—…ë£Œ: N/A\n")
                    if pd.notna(a['íšŒë‹¨ê°€']):
                        f.write(f"   â€¢ 1íšŒ ë‹¨ê°€: {a['íšŒë‹¨ê°€']:,.0f}ì›\n")
                    if pd.notna(a['ë“±ë¡ë¹„ìš©']):
                        f.write(f"   â€¢ ë“±ë¡ë¹„ìš©: {a['ë“±ë¡ë¹„ìš©']:,.0f}ì›\n")
                    if pd.notna(a['ê³µê¸‰ê°€']):
                        f.write(f"   â€¢ ê³µê¸‰ê°€: {a['ê³µê¸‰ê°€']:,.0f}ì›\n")

                    # íšŒì› DB ì •ë³´
                    f.write(f"\n   [íšŒì› DB ì •ë³´]\n")
                    f.write(f"   â€¢ íšŒì› ìƒíƒœ: {a['íšŒì›ìƒíƒœ']}\n")
                    if pd.notna(a['ì—°ë½ì²˜']):
                        f.write(f"   â€¢ ì—°ë½ì²˜: {a['ì—°ë½ì²˜']}\n")
                    if pd.notna(a['ìµœì¢…ë§Œë£Œì¼']):
                        days_str = f" (D-{int(a['ë‚¨ì€ì¼ìˆ˜'])})" if pd.notna(a['ë‚¨ì€ì¼ìˆ˜']) else ""
                        f.write(f"   â€¢ ìµœì¢… ë§Œë£Œì¼: {a['ìµœì¢…ë§Œë£Œì¼']}{days_str}\n")
                    if pd.notna(a['ìµœê·¼ì¶œì„ì¼']):
                        f.write(f"   â€¢ ìµœê·¼ ì¶œì„ì¼: {a['ìµœê·¼ì¶œì„ì¼']}\n")
                    if pd.notna(a['íšŒì›DB_ë‹´ë‹¹ì']) and a['íšŒì›DB_ë‹´ë‹¹ì'] != '-':
                        f.write(f"   â€¢ DBìƒ ë‹´ë‹¹ì: {a['íšŒì›DB_ë‹´ë‹¹ì']}\n")

                    # ë¬¸ì œì 
                    f.write(f"\n   [ë¬¸ì œì ]\n")
                    for issue in a['issues']:
                        f.write(f"   âš ï¸  {issue}\n")

                    f.write("\n")

        # ì£¼ìš” ë°œê²¬ì‚¬í•­
        f.write(f"\n\n{'='*120}\n")
        f.write("ğŸ’¡ ì£¼ìš” ë°œê²¬ì‚¬í•­ ìš”ì•½\n")
        f.write(f"{'='*120}\n\n")

        # 0. ğŸš¨ ì–´ë·°ì§• ì˜ì‹¬ (10-11ì›”)
        abuse_suspected = [a for a in anomalies if a['in_db'] and a['ì›”'] in ['10ì›”', '11ì›”'] and
                          any('ì–´ë·°ì§• ì˜ì‹¬' in issue for issue in a['issues'])]
        if abuse_suspected:
            total_amount = sum(a['ë‹¹ì›”ìˆ˜ì—…ë£Œ'] for a in abuse_suspected if pd.notna(a['ë‹¹ì›”ìˆ˜ì—…ë£Œ']))
            f.write(f"ğŸš¨ ì–´ë·°ì§• ì˜ì‹¬ (10-11ì›”): {len(abuse_suspected)}ê±´\n")
            f.write(f"   ì´ ì§€ê¸‰ì•¡: {total_amount:,.0f}ì›\n")
            f.write(f"   10-11ì›” ì „ì›” ì”ì—¬ì„¸ì…˜ì´ ë¶€ì¡±í•œë°ë„ ì„¸ì…˜ì´ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.\n")
            f.write(f"   ì´ìš©ê¶Œ ì¶”ê°€ êµ¬ë§¤ ì—†ì´ ì§„í–‰ëœ ê²ƒìœ¼ë¡œ ì˜ì‹¬ë©ë‹ˆë‹¤.\n\n")
            for a in abuse_suspected[:15]:
                for issue in a['issues']:
                    if 'ì–´ë·°ì§• ì˜ì‹¬' in issue:
                        f.write(f"   â€¢ {a['íšŒì›ëª…']} ({a['íŠ¸ë ˆì´ë„ˆ']}, {a['ì›”']}): {issue}\n")
                        break
            if len(abuse_suspected) > 15:
                f.write(f"   ... ì™¸ {len(abuse_suspected)-15}ê±´\n")
            f.write("\n")

        # 1. ì„¸ì…˜ ì§„í–‰ ë‹¹ì‹œ ë§Œë£Œëœ íšŒì› ì¤‘ ì„¸ì…˜ ì§„í–‰
        expired_sessions = [a for a in anomalies if a['in_db'] and
                          any('ì„¸ì…˜ ì§„í–‰ ë‹¹ì‹œ' in issue and 'ì´ë¯¸ ë§Œë£Œ' in issue for issue in a['issues'])]
        if expired_sessions:
            total_amount = sum(a['ë‹¹ì›”ìˆ˜ì—…ë£Œ'] for a in expired_sessions if pd.notna(a['ë‹¹ì›”ìˆ˜ì—…ë£Œ']))
            f.write(f"1. ì„¸ì…˜ ì§„í–‰ ë‹¹ì‹œ ë§Œë£Œëœ íšŒì›: {len(expired_sessions)}ê±´\n")
            f.write(f"   ì´ ì§€ê¸‰ì•¡: {total_amount:,.0f}ì›\n")
            f.write(f"   ì„¸ì…˜ ì§„í–‰ ì›” ê¸°ì¤€ìœ¼ë¡œ ì´ë¯¸ íšŒì›ê¶Œì´ ë§Œë£Œë˜ì—ˆëŠ”ë°ë„ ì„¸ì…˜ì´ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n")
            for a in expired_sessions[:10]:
                expire_info = f" (ë§Œë£Œì¼: {a['ìµœì¢…ë§Œë£Œì¼']})" if pd.notna(a['ìµœì¢…ë§Œë£Œì¼']) else ""
                f.write(f"   â€¢ {a['íšŒì›ëª…']} ({a['íŠ¸ë ˆì´ë„ˆ']}, {a['ì›”']}): {a['ë‹¹ì›”ì§„í–‰ì„¸ì…˜']:.0f}íšŒ, {a['ë‹¹ì›”ìˆ˜ì—…ë£Œ']:,.0f}ì›{expire_info}\n")
            if len(expired_sessions) > 10:
                f.write(f"   ... ì™¸ {len(expired_sessions)-10}ê±´\n")
            f.write("\n")

        # 2. ë‹´ë‹¹ì ë¶ˆì¼ì¹˜
        trainer_mismatch = [a for a in anomalies if a['in_db'] and
                           'ë‹´ë‹¹ì ë¶ˆì¼ì¹˜' in str(a['issues'])]
        if trainer_mismatch:
            f.write(f"2. ë‹´ë‹¹ì ë¶ˆì¼ì¹˜: {len(trainer_mismatch)}ê±´\n")
            f.write(f"   ê¸‰ì—¬ ì‹œíŠ¸ì˜ íŠ¸ë ˆì´ë„ˆì™€ íšŒì› DBì˜ ë‹´ë‹¹ìê°€ ë‹¤ë¦…ë‹ˆë‹¤.\n\n")
            for a in trainer_mismatch[:10]:
                f.write(f"   â€¢ {a['íšŒì›ëª…']}: ê¸‰ì—¬({a['íŠ¸ë ˆì´ë„ˆ']}) â‰  DB({a['íšŒì›DB_ë‹´ë‹¹ì']})\n")
            if len(trainer_mismatch) > 10:
                f.write(f"   ... ì™¸ {len(trainer_mismatch)-10}ê±´\n")
            f.write("\n")

        # 3. ì„¸ì…˜ ì¢…ë£Œ í›„ ì§„í–‰
        zero_remaining = [a for a in anomalies if 'ë‚¨ì€ì„¸ì…˜ 0' in str(a['issues']) or 'ë‚¨ì€ì„¸ì…˜ -' in str(a['issues'])]
        if zero_remaining:
            f.write(f"3. ì„¸ì…˜ ì¢…ë£Œ í›„ ì§„í–‰: {len(zero_remaining)}ê±´\n")
            f.write(f"   ë‚¨ì€ ì„¸ì…˜ì´ 0 ì´í•˜ì¸ë° ë‹¹ì›” ì„¸ì…˜ì´ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n")
            for a in zero_remaining[:10]:
                f.write(f"   â€¢ {a['íšŒì›ëª…']} ({a['íŠ¸ë ˆì´ë„ˆ']}): ë‹¹ì›” {a['ë‹¹ì›”ì§„í–‰ì„¸ì…˜']:.0f}íšŒ ì§„í–‰\n")
            if len(zero_remaining) > 10:
                f.write(f"   ... ì™¸ {len(zero_remaining)-10}ê±´\n")
            f.write("\n")

        # 4. ì„¸ì…˜ ì°¨ê° ì´ìƒ (ë¹„ì •ìƒ ì¦ê°€)
        session_deduction_issues = [a for a in anomalies if 'ì„¸ì…˜ ì°¨ê° ì´ìƒ' in str(a['issues'])]
        if session_deduction_issues:
            f.write(f"4. ì„¸ì…˜ ì°¨ê° ì´ìƒ (ë¹„ì •ìƒ ì¦ê°€): {len(session_deduction_issues)}ê±´\n")
            f.write(f"   ì „ì›” ì”ì—¬ - ë‹¹ì›” ì§„í–‰ = ì˜ˆìƒê°’ê³¼ ì‹¤ì œ ì”ì—¬ê°€ ë‹¤ë¦…ë‹ˆë‹¤ (ì„¸ì…˜ ì¦ê°€).\n\n")
            for a in session_deduction_issues[:10]:
                for issue in a['issues']:
                    if 'ì„¸ì…˜ ì°¨ê° ì´ìƒ' in issue:
                        f.write(f"   â€¢ {a['íšŒì›ëª…']} ({a['íŠ¸ë ˆì´ë„ˆ']}): {issue}\n")
                        break
            if len(session_deduction_issues) > 10:
                f.write(f"   ... ì™¸ {len(session_deduction_issues)-10}ê±´\n")
            f.write("\n")

        # 5. ì„¸ì…˜ ì¶”ê°€ ì°¨ê°
        session_extra_deduction = [a for a in anomalies if 'ì„¸ì…˜ ì¶”ê°€ ì°¨ê°' in str(a['issues'])]
        if session_extra_deduction:
            f.write(f"5. ì„¸ì…˜ ì¶”ê°€ ì°¨ê°: {len(session_extra_deduction)}ê±´\n")
            f.write(f"   ì „ì›” ì”ì—¬ - ë‹¹ì›” ì§„í–‰ë³´ë‹¤ ë” ë§ì´ ì°¨ê°ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n")
            for a in session_extra_deduction[:10]:
                for issue in a['issues']:
                    if 'ì„¸ì…˜ ì¶”ê°€ ì°¨ê°' in issue:
                        f.write(f"   â€¢ {a['íšŒì›ëª…']} ({a['íŠ¸ë ˆì´ë„ˆ']}): {issue}\n")
                        break
            if len(session_extra_deduction) > 10:
                f.write(f"   ... ì™¸ {len(session_extra_deduction)-10}ê±´\n")
            f.write("\n")

def create_versioned_report_dir(base_dir):
    """ë²„ì €ë‹ëœ ë³´ê³ ì„œ ë””ë ‰í† ë¦¬ ìƒì„±"""
    reports_dir = base_dir / "pay" / "reports"
    reports_dir.mkdir(parents=True, exist_ok=True)

    # íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ ë””ë ‰í† ë¦¬ëª…
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_dir = reports_dir / timestamp
    report_dir.mkdir(parents=True, exist_ok=True)

    # latest ì‹¬ë³¼ë¦­ ë§í¬ ì—…ë°ì´íŠ¸ (Windowsì—ì„œëŠ” ë³µì‚¬)
    latest_link = reports_dir / "latest"
    if latest_link.exists():
        if latest_link.is_symlink():
            latest_link.unlink()
        elif latest_link.is_dir():
            shutil.rmtree(latest_link)

    try:
        # Unix/Macì—ì„œëŠ” ì‹¬ë³¼ë¦­ ë§í¬
        latest_link.symlink_to(timestamp, target_is_directory=True)
    except (OSError, NotImplementedError):
        # Windowsì—ì„œëŠ” ê·¸ëƒ¥ ë³µì‚¬í•˜ì§€ ì•Šê³  íŒ¨ìŠ¤
        pass

    return report_dir, timestamp

def copy_comprehensive_report(base_dir, report_dir):
    """ì¢…í•©ë¶„ì„ë³´ê³ ì„œë¥¼ ë³´ê³ ì„œ ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬"""
    source = base_dir / "pay" / "Doubless_ì¢…í•©ë¶„ì„ë³´ê³ ì„œ.md"
    if source.exists():
        dest = report_dir / "ì¢…í•©ë¶„ì„ë³´ê³ ì„œ.md"
        shutil.copy(source, dest)
        print(f"âœ… ì¢…í•©ë¶„ì„ë³´ê³ ì„œ ë³µì‚¬ ì™„ë£Œ")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("="*120)
    print("ğŸ’° ê¸‰ì—¬ ì´ìƒê±´ ì¢…í•© ë¶„ì„ (DB ê¸°ë°˜)")
    print("="*120)

    # ê²½ë¡œ ì„¤ì •
    base_dir = Path(__file__).parent.parent
    salary_db = base_dir / "data" / "doubless.db"
    members_db = base_dir / "data" / "doubless.db"

    # ë²„ì €ë‹ëœ ë³´ê³ ì„œ ë””ë ‰í† ë¦¬ ìƒì„±
    report_dir, timestamp = create_versioned_report_dir(base_dir)
    print(f"\nğŸ“ ë³´ê³ ì„œ ë””ë ‰í† ë¦¬: reports/{timestamp}/")

    # DB í™•ì¸
    if not salary_db.exists():
        print(f"âŒ ê¸‰ì—¬ DBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {salary_db}")
        return

    if not members_db.exists():
        print(f"âŒ íšŒì› DBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {members_db}")
        return

    # ì´ë¦„ ë§¤í•‘ ê·œì¹™ ë¡œë“œ
    print("\nğŸ“‹ ì´ë¦„ ë§¤í•‘ ê·œì¹™ ë¡œë“œ ì¤‘...")
    name_rules = load_name_mapping_rules()
    print(f"âœ… ì •ê·œí™” ê·œì¹™: {len(name_rules['normalization_rules']['rules'])}ê°œ")
    print(f"âœ… ì•Œë ¤ì§„ ë§¤í•‘: {len(name_rules['known_mappings']['mappings'])}ê°œ")

    # ë°ì´í„° ë¡œë“œ
    print("\nğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
    df = load_salary_and_members(salary_db, members_db, name_rules)
    print(f"âœ… {len(df)}ê±´ì˜ ê¸‰ì—¬ ë ˆì½”ë“œ ë¡œë“œ ì™„ë£Œ")

    # ì´ë¦„ ë§¤í•‘ ì ìš© í†µê³„
    mapped_count = df['ì´ë¦„_ë§¤í•‘_ì ìš©'].sum()
    if mapped_count > 0:
        print(f"âœ… ì´ë¦„ ë§¤í•‘ ì ìš©: {mapped_count}ê±´")
        mapped_cases = df[df['ì´ë¦„_ë§¤í•‘_ì ìš©']][['ì›ë³¸_íšŒì›ëª…', 'íšŒì›ëª…_ì •ê·œí™”']].drop_duplicates()
        for _, row in mapped_cases.iterrows():
            print(f"   â€¢ {row['ì›ë³¸_íšŒì›ëª…']} â†’ {row['íšŒì›ëª…_ì •ê·œí™”']}")

    # ì´ìƒê±´ íƒì§€
    print("\nğŸ” ì´ìƒê±´ íƒì§€ ì¤‘...")
    anomalies = detect_anomalies(df)
    print(f"âœ… {len(anomalies)}ê±´ì˜ ì´ìƒê±´ ë°œê²¬")

    # ë³´ê³ ì„œ ì €ì¥
    print(f"\nğŸ“ ë³´ê³ ì„œ ìƒì„± ì¤‘...")

    # 1. ìƒì„¸ í…ìŠ¤íŠ¸ ë³´ê³ ì„œ
    detail_report = report_dir / "ê¸‰ì—¬ì´ìƒê±´_ìƒì„¸.txt"
    save_analysis_report(anomalies, detail_report)
    print(f"âœ… ìƒì„¸ ë³´ê³ ì„œ: {detail_report.name}")

    # 2. ì´ìƒê±´ CSV (ì—‘ì…€ìš©)
    csv_file = report_dir / "ì´ìƒê±´_ëª©ë¡.csv"
    save_anomalies_csv(anomalies, csv_file)
    print(f"âœ… ì´ìƒê±´ CSV: {csv_file.name}")

    # 3. ë©”íƒ€ë°ì´í„° JSON
    save_metadata(report_dir, anomalies, len(df))
    print(f"âœ… ë©”íƒ€ë°ì´í„°: ë¶„ì„_ë©”íƒ€ë°ì´í„°.json")

    # 4. ì¢…í•©ë¶„ì„ë³´ê³ ì„œ ë³µì‚¬
    copy_comprehensive_report(base_dir, report_dir)

    # ìš”ì•½ ì¶œë ¥
    in_db = sum(1 for a in anomalies if a['in_db'])
    not_in_db = len(anomalies) - in_db

    print(f"\n" + "="*120)
    print(f"ğŸ“Š ë¶„ì„ ì™„ë£Œ")
    print(f"="*120)
    print(f"ì´ ê¸‰ì—¬ ë ˆì½”ë“œ: {len(df)}ê±´")
    print(f"ì´ ì´ìƒê±´: {len(anomalies)}ê±´ ({len(anomalies)*100/len(df):.1f}%)")
    print(f"  â€¢ íšŒì› DB ì¡´ì¬: {in_db}ê±´")
    print(f"  â€¢ íšŒì› DB ì—†ìŒ: {not_in_db}ê±´")
    print(f"\në³´ê³ ì„œ ìœ„ì¹˜: {report_dir}")
    print(f"  - ê¸‰ì—¬ì´ìƒê±´_ìƒì„¸.txt")
    print(f"  - ì´ìƒê±´_ëª©ë¡.csv")
    print(f"  - ë¶„ì„_ë©”íƒ€ë°ì´í„°.json")
    print(f"  - ì¢…í•©ë¶„ì„ë³´ê³ ì„œ.md")

if __name__ == "__main__":
    main()
